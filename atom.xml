<feed xmlns="http://www.w3.org/2005/Atom">
	<author>
		<name>
			David v.Knobelsdorff
		</name>
	</author>
	<title type="text">davidvonk.dev</title>
	<id>https://davidvonk.dev</id>
	<updated>2025-06-04T18:15:00Z</updated>
	<link href="https://davidvonk.dev/atom.xml" rel="self">
	</link>
	<entry>
		<title type="text">Building a homelab (5/5): Everything else</title>
		<id>https://davidvonk.dev/homelab/building-a-homelab-5-5-everything-else</id>
		<link href="https://davidvonk.dev/homelab/building-a-homelab-5-5-everything-else" rel="alternate">
		</link>
		<updated>2025-06-04T18:15:00Z</updated>
		<summary type="text">
			A blog post series about my journey building a homelab
		</summary>
		<content type="html">
			&lt;blockquote&gt;
	&lt;p&gt;
		Why did the homelabber bring a book to the server room? Because with so much to learn, they needed a backup plan for their brain!
	&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;
	In the last 4 blog posts we learned a lot about building a homelab and what even is possible. However there are still a lot of topics to dive into. In this last post I want to have a quick look at a few of them.
&lt;/p&gt;
&lt;h2&gt;
	Task scheduling with cron
&lt;/h2&gt;
&lt;p&gt;
	On my homeserver I not only run a handful of services I also need to schedule tasks throughout the day. These involve the renovate bot discussed in part 2 but also backup tasks etc. When implementing this I took a deep dive into cron which I want to share with you here.
&lt;/p&gt;
&lt;p&gt;&lt;code&gt;cron&lt;/code&gt; is a time-based job scheduler in Unix-like systems, including Ubuntu. It allows users and administrators to schedule scripts or commands to run at specific times or intervals automatically. It is widely used for repetitive tasks like backups, system maintenance, or monitoring.
&lt;/p&gt;
&lt;p&gt;
	Ubuntu uses &lt;code&gt;cron&lt;/code&gt; via the &lt;code&gt;cron&lt;/code&gt; package, which installs the daemon and required configuration directories.
&lt;/p&gt;
&lt;h3&gt;
	Adding a New Cron Job (Using &lt;code&gt;/etc/cron.d/&lt;/code&gt;)
&lt;/h3&gt;
&lt;p&gt;
	To add a system-level cron job, create a file in &lt;code&gt;/etc/cron.d/&lt;/code&gt;:
&lt;/p&gt;
&lt;h4&gt;
	Example: &lt;code&gt;/etc/cron.d/myjob&lt;/code&gt;&lt;/h4&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-cron&quot;&gt;# Run a script every day at 2:30 AM
30 2 * * * root /usr/local/bin/myscript.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;ul&gt;
	&lt;li&gt;
		&lt;p&gt;
			The file must be owned by &lt;code&gt;root&lt;/code&gt; and should have permissions &lt;code&gt;644&lt;/code&gt;.
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Always specify the &lt;strong&gt;user&lt;/strong&gt; to run the command (e.g., &lt;code&gt;root&lt;/code&gt;, &lt;code&gt;ubuntu&lt;/code&gt;, etc.).
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
	Set permissions with:
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;sudo chmod 644 /etc/cron.d/myjob
sudo chown root:root /etc/cron.d/myjob
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;h3&gt;
	Cron Timing Syntax
&lt;/h3&gt;
&lt;table&gt;
	&lt;thead&gt;
		&lt;tr&gt;
			&lt;th&gt;
				Field
			&lt;/th&gt;
			&lt;th&gt;
				Allowed Values
			&lt;/th&gt;
			&lt;th&gt;
				Description
			&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Minute
			&lt;/td&gt;
			&lt;td&gt;
				0–59
			&lt;/td&gt;
			&lt;td&gt;
				Minute of the hour
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Hour
			&lt;/td&gt;
			&lt;td&gt;
				0–23
			&lt;/td&gt;
			&lt;td&gt;
				Hour of the day
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Day of Month
			&lt;/td&gt;
			&lt;td&gt;
				1–31
			&lt;/td&gt;
			&lt;td&gt;
				Day of the month
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Month
			&lt;/td&gt;
			&lt;td&gt;
				1–12 or Jan–Dec
			&lt;/td&gt;
			&lt;td&gt;
				Month of the year
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Day of Week
			&lt;/td&gt;
			&lt;td&gt;
				0–7 or Sun–Sat
			&lt;/td&gt;
			&lt;td&gt;
				Day of the week (0 or 7 is Sunday)
			&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4&gt;
	Special Symbols
&lt;/h4&gt;
&lt;table&gt;
	&lt;thead&gt;
		&lt;tr&gt;
			&lt;th&gt;
				Symbol
			&lt;/th&gt;
			&lt;th&gt;
				Meaning
			&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;
				`*`
			&lt;/td&gt;
			&lt;td&gt;
				Every possible value
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				`,`
			&lt;/td&gt;
			&lt;td&gt;
				Value list separator
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				`-`
			&lt;/td&gt;
			&lt;td&gt;
				Range of values
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				`/`
			&lt;/td&gt;
			&lt;td&gt;
				Step values (e.g., `*/5`)
			&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;
	Checking if a Cron Job Runs
&lt;/h3&gt;
&lt;ol&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;Check Logs&lt;/strong&gt;&lt;/p&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;grep CRON /var/log/syslog
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;p&gt;
	Or for recent entries:
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;journalctl -u cron.service
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;ol&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;Add Logging in Your Script&lt;/strong&gt;&lt;/p&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
	Add output redirection in your cron job:
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-cron&quot;&gt;30 2 * * * root /usr/local/bin/myscript.sh &amp;gt;&amp;gt; /var/log/myscript.log 2&amp;gt;&amp;amp;1
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;h3&gt;
	Restarting Cron to Enable New Jobs
&lt;/h3&gt;
&lt;p&gt;
	After adding or modifying files in &lt;code&gt;/etc/cron.d/&lt;/code&gt;, restart the cron service:
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;sudo systemctl restart cron
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;p&gt;
	To check cron status:
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;systemctl status cron
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;p&gt;
	Ensure that the new job file is valid and has the proper permissions. Invalid files or missing users will cause the job to be ignored.
&lt;/p&gt;
&lt;h2&gt;
	Rotating log files with logrotate
&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;logrotate&lt;/code&gt; is a utility used on Ubuntu (and other Linux distributions) to manage the automatic rotation, compression, removal, and mailing of log files. It helps prevent logs from consuming too much disk space and keeps log directories organized.
&lt;/p&gt;
&lt;p&gt;
	On Ubuntu, &lt;code&gt;logrotate&lt;/code&gt; is typically run daily via a cron job managed by &lt;code&gt;systemd&lt;/code&gt; timer units.
&lt;/p&gt;
&lt;p&gt;
	Ubuntu uses &lt;code&gt;systemd&lt;/code&gt; to manage scheduled tasks. You can check the timer for logrotate using:
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;systemctl status logrotate.timer
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;h3&gt;
	Defining a Custom Rule
&lt;/h3&gt;
&lt;p&gt;
	To rotate logs for a custom application, create a file in &lt;code&gt;/etc/logrotate.d/&lt;/code&gt;:
&lt;/p&gt;
&lt;h4&gt;
	Example: &lt;code&gt;/etc/logrotate.d/myapp&lt;/code&gt;&lt;/h4&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-conf&quot;&gt;/var/log/myapp/*.log {
    daily
    missingok
    rotate 14
    compress
    delaycompress
    notifempty
    create 0640 myuser mygroup
    sharedscripts
    postrotate
        systemctl reload myapp.service &amp;gt; /dev/null 2&amp;gt;/dev/null || true
    endscript
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;h4&gt;
	Explanation of Options
&lt;/h4&gt;
&lt;table&gt;
	&lt;thead&gt;
		&lt;tr&gt;
			&lt;th&gt;
				Option
			&lt;/th&gt;
			&lt;th&gt;
				Description
			&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;
				`daily`
			&lt;/td&gt;
			&lt;td&gt;
				Rotate logs every day
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				`missingok`
			&lt;/td&gt;
			&lt;td&gt;
				Do not show error if log file is missing
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				`rotate 14`
			&lt;/td&gt;
			&lt;td&gt;
				Keep 14 old log files before deleting
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				`compress`
			&lt;/td&gt;
			&lt;td&gt;
				Compress rotated logs (using gzip by default)
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				`delaycompress`
			&lt;/td&gt;
			&lt;td&gt;
				Delay compression until the next rotation (useful with apps that keep logs open)
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				`notifempty`
			&lt;/td&gt;
			&lt;td&gt;
				Do not rotate empty log files
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				`create`
			&lt;/td&gt;
			&lt;td&gt;
				Create a new log file with specified permissions and ownership
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				`sharedscripts`
			&lt;/td&gt;
			&lt;td&gt;
				Run `postrotate` script once, even if multiple logs are matched
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				`postrotate`
			&lt;/td&gt;
			&lt;td&gt;
				Script to run after rotation (e.g., to reload services)
			&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;
	Testing a Logrotate Rule
&lt;/h3&gt;
&lt;p&gt;
	To simulate and debug log rotation without making changes:
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;sudo logrotate -d /etc/logrotate.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;p&gt;
	To force log rotation:
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;sudo logrotate -f /etc/logrotate.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;p&gt;
	To test a specific configuration file:
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;sudo logrotate -d /etc/logrotate.d/myapp
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;p&gt;
	Check &lt;code&gt;/var/lib/logrotate/status&lt;/code&gt; to see the last time files were rotated.
&lt;/p&gt;
&lt;h2&gt;
	Proxmox Hypervisor
&lt;/h2&gt;
&lt;p&gt;
	As a blogger showcasing my private homelab, I can confidently say that Proxmox Hypervisor is a game-changer for anyone looking to dive into virtualization. Being open-source, it not only provides a cost-effective solution but also comes with a thriving community that’s always ready to help and share knowledge. The combination of KVM and LXC allows me to run both virtual machines and containers seamlessly, while its user-friendly web interface makes management a breeze. With features like live migration and built-in backup solutions, I can experiment with different setups without worrying about downtime. Proxmox has truly empowered my homelab journey, making it a solid choice for maximizing my hardware and exploring new possibilities!
&lt;/p&gt;
&lt;h2&gt;
	Backups
&lt;/h2&gt;
&lt;p&gt;
	I’ve implemented a robust 3-2-1 backup strategy using two Synology NAS storage solutions alongside a Proxmox Backup Server for all my VMs running in the Proxmox Hypervisor. This approach ensures that I have three copies of my data, stored on two different types of media, with one copy kept offsite for added security.
&lt;/p&gt;
&lt;p&gt;
	The Proxmox Backup Server allows for incredibly fast snapshot backups, enabling me to capture the state of my VMs almost instantly without significant downtime.
&lt;/p&gt;
&lt;p&gt;
	To ensure the integrity of my backups, I regularly verify checksums, which helps confirm that my data is stable and recoverable.
&lt;/p&gt;
&lt;p&gt;
	In the event of a failure, restoring from these backups is straightforward and efficient, giving me peace of mind that my homelab is well-protected against data loss. This comprehensive backup strategy not only safeguards my projects but also allows me to experiment and innovate without fear!
&lt;/p&gt;
&lt;h2&gt;
	Hardening SSH access
&lt;/h2&gt;
&lt;p&gt;
	Hardening SSH access to my private machines is essential for enhancing security, and there are a few straightforward steps I take to achieve this.
&lt;/p&gt;
&lt;p&gt;
	First, I change the default SSH port from 22 to something less predictable by creating a separate configuration file in the &lt;code&gt;/etc/ssh/sshd_config.d/&lt;/code&gt; directory, which allows me to add my custom settings without cluttering the main &lt;code&gt;sshd_config&lt;/code&gt; file. This modular approach not only keeps my configurations organized but also makes it easier to manage and troubleshoot changes in the future.
&lt;/p&gt;
&lt;p&gt;
	Next, I create a convenient SSH config file at &lt;code&gt;~/.ssh/config&lt;/code&gt; to streamline my connections, adding entries like &lt;code&gt;Host myserver&lt;/code&gt; followed by &lt;code&gt;HostName myserver.example.com&lt;/code&gt; and &lt;code&gt;Port 2222&lt;/code&gt; (or whatever port I chose).
&lt;/p&gt;
&lt;p&gt;
	Most importantly, I configure SSH to use only public key authentication by setting &lt;code&gt;PasswordAuthentication no&lt;/code&gt; in my custom config file. This approach significantly reduces the risk of brute-force attacks, as it requires a private key for access, making it a best practice for securing my homelab environment.
&lt;/p&gt;
&lt;h2&gt;
	Filesystems
&lt;/h2&gt;
&lt;h3&gt;
	Btrfs on Synology NAS
&lt;/h3&gt;
&lt;p&gt;
	In my homelab, I run Btrfs on two Synology NAS machines, taking advantage of its advanced features like snapshotting, built-in RAID, and efficient data compression. Btrfs allows me to create point-in-time snapshots of my data, making it easy to roll back to previous states in case of accidental deletions or corruption. Additionally, its self-healing capabilities ensure data integrity by automatically detecting and repairing errors, providing me with peace of mind.
&lt;/p&gt;
&lt;h3&gt;
	ZFS on Proxmox Host
&lt;/h3&gt;
&lt;p&gt;
	On my Proxmox host, I utilize ZFS on NVMe SSDs, which offers exceptional performance and reliability. ZFS is renowned for its robust data protection features, including checksumming for data integrity and the ability to create snapshots and clones efficiently. The combination of ZFS&apos;s advanced RAID options allows me to choose an appropriate RAID type that balances redundancy and performance, ensuring that my virtual machines are both fast and secure.
&lt;/p&gt;
&lt;h3&gt;
	Redundancy and Reliability
&lt;/h3&gt;
&lt;p&gt;
	By leveraging both Btrfs and ZFS, I have created a resilient storage architecture in my homelab. The RAID configurations on both systems provide redundancy, safeguarding my data against hardware failures while allowing me to enjoy the unique strengths of each filesystem. This thoughtful approach to storage not only enhances performance but also ensures that my data remains safe and accessible, no matter the circumstances.
&lt;/p&gt;
		</content>
	</entry>
	<entry>
		<title type="text">Building a homelab (4/5): Networking, VLANs and VPN</title>
		<id>https://davidvonk.dev/homelab/building-a-homelab-4-5-networking-vlans-and-vpn</id>
		<link href="https://davidvonk.dev/homelab/building-a-homelab-4-5-networking-vlans-and-vpn" rel="alternate">
		</link>
		<updated>2025-06-04T17:15:00Z</updated>
		<summary type="text">
			A blog post series about my journey building a homelab
		</summary>
		<content type="html">
			&lt;blockquote&gt;
	&lt;p&gt;
		Why did the data cross the road? To get to the VLAN on the other side!.
	&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;
	When we moved into our new home new CAT 7 cables were run throughout the whole house. That was the reason I wanted to get into networking infrastructure and to build my home network more professionally. Of course when you setup all this networking infrastructure you want to utilize it as well and so this blog post and my excitement for homelabs was born. When I shopped the new network gear I tried to plan ahead which is why the new devices are all Wifi 7 capable and I am able to utilize 10 GB SFP+ ports on my switch for some devices (f.e. for my NAS). To get things started here is a diagram of the deployed networking infrastructure:
&lt;/p&gt;
&lt;div class=&quot;image&quot;&gt;
	&lt;img alt=&quot;An image showing a diagram of my network infrastructure.&quot; loading=&quot;lazy&quot; src=&quot;/img/building-a-homelab/network.png&quot; width=&quot;463.5&quot;/&gt;
&lt;/div&gt;
&lt;h2&gt;
	VLANs
&lt;/h2&gt;
&lt;p&gt;
	To segregate my network I make use of VLANs. This is important to me first and foremost to improve the security of my network. F.e. IoT devices do not get access to any other devices in my home. If not necessary they won&apos;t get internet access either!
&lt;/p&gt;
&lt;p&gt;
	I also deploy a VLAN especially for the devices of my kids. This way I can add specific content filters for their devices which I do not want to deploy on a device to device basis or on the main network. I am able to securely host servers in a DMZ or provide guests with a guest network. At the moment my current setup looks like this:
&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;
		&lt;p&gt;
			VLAN1: Default
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			VLAN10: Trusted
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			VLAN20: IOT
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			VLAN30: Kids
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			VLAN90: Guest
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			VLAN254: Management
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
	I also disabled the auto-scale network option in the VLAN settings. With that I can set static IPs in the range 192.168.VLANID.1 - 192.168.VLANID.100. Everything above 100 is an IP address provided via DHCP. Whenever I see an IP address in my network I can quickly glance at it and directly extract the information whether it is a static or dynamic IP address and which VLAN it is in.
&lt;/p&gt;
&lt;p&gt;
	To secure the VLANs I deploy the new zone-based firewall from Unifi in my network. By default Unifi routes between VLANs. I opted for blocking access between VLANs by default and only allowing the absolute minimum needed. For example my trusted devices can access IoT devices to control the lighting but the lights itself do not have access to any other devices deployed in my infrastructure.
&lt;/p&gt;
&lt;h2&gt;
	🌐 VPN
&lt;/h2&gt;
&lt;p&gt;
	In a previous part I told you that I run my services in my LAN only. However sometimes you are on the go and still want access to your passwords/media library/etc... .
	
	The problem with most internet service providers in Germany nowadays is that you won&apos;t get a static IPv4 address any longer. This isn&apos;t technically an issue but it leads to a bit more work for us to successfully connect through a VPN connection into our local network. It boils down to two options:
&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;
		&lt;p&gt;
			Use a DynDNS service to automatically send your dynamic IPv4 address to this service which then can resolve your current public IPv4 address for a given hostname
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			If you do not get an IPv4 address at all (Carrier Grade NAT) the first solution might not work for you when trying to utilize your VPN connection over IPv6 only. You can use a VPS with a static IPv4 addres however and tunnel all traffic to your home infrastructure through a site-to-site VPN tunnel.
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
	At the moment I could use option 1, however I already know that the ISP bringing fiber optics to our home will only provide CGNat. To be future proof I opted for option 2 and rented a cheap VPS for 0,50€ / month.
&lt;/p&gt;
&lt;p&gt;
	Here are the steps I took to create this tunnel:
&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;
		&lt;p&gt;
			Install wireguard on VPS
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Open the wireguard tunnel port in the firewall
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Create a port forwarding in &lt;code&gt;/etc/sysctl.conf&lt;/code&gt; to forward all IPv4 traffic
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Create secure wireguard key pairs
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Create a wireguard config to connect this wireguard server to a wireguard client in your home network. It is recommended to list every possible peer seperate to be able to better control who has access to this VPN connection
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Start the wireguard server
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
	I then created a wireguard client on my Unifi Router and connected it to the deployed wireguard server. I also added a static route and the needed firewall rules on my router to be able to access the needed devices in my infrastructure from the private VPN network.
&lt;/p&gt;
&lt;p&gt;
	The last step is to add a wireguard client to your private devices and add a config to it. If everything is setup correctly your device (f.e. Smartphone) will connect to the public IPv4 address of your VPS. Every request is then forwarded through the existing VPN tunnel connection to your router where the VPN client is active.
&lt;/p&gt;
&lt;h2&gt;
	📞 Addendum: Telephony
&lt;/h2&gt;
&lt;p&gt;
	When I migrated from my former setup to the new Unifi devices one problem was left to be solved: telephony. The old router could be used as a telephone base station speaking the DECT protocol. Fortunately my old router has the option to function as an IP-Client and to use an existing internet connection. I set it up like that and disabled any WLAN networks. If you have the same situation in your network currently I strongly suggest to look for an option like that as this setup seems to work perfectly fine.
&lt;/p&gt;
&lt;h2&gt;
	➡️ Up Next
&lt;/h2&gt;
&lt;p&gt;
	In the last part I want to draw a conclusion and talk about all the topics I did not mention yet:
&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;
		&lt;p&gt;
			Task scheduling with cron
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Rotating log files with logrotate
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Proxmox Hypervisor
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Backups
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Hardening SSH access
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Filesystems
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ul&gt;
		</content>
	</entry>
	<entry>
		<title type="text">Building a homelab (3/5): Containerized Services: DNS, Monitoring, and Self-Hosted Apps</title>
		<id>https://davidvonk.dev/homelab/building-a-homelab-3-5-containerized-services-dns-monitoring-and-self-hosted-apps</id>
		<link href="https://davidvonk.dev/homelab/building-a-homelab-3-5-containerized-services-dns-monitoring-and-self-hosted-apps" rel="alternate">
		</link>
		<updated>2025-06-04T16:15:00Z</updated>
		<summary type="text">
			A blog post series about my journey building a homelab
		</summary>
		<content type="html">
			&lt;blockquote&gt;
	&lt;p&gt;
		Empower your digital life: In a world of clouds, I choose to build my own — where privacy reigns and my data is truly mine.
	&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;
	In Part 1, I introduced my homelab setup. In Part 2, I covered the GitOps pipeline with Renovate and Komodo. Now let’s look at the actual applications that make this environment useful.
&lt;/p&gt;
&lt;p&gt;
	From local DNS blocking to RSS reading and media streaming, everything is self-hosted. And since I’m running on a mix of Pi boards and a Proxmox VM, distribution of services matters just as much as the apps themselves.
&lt;/p&gt;
&lt;h2&gt;
	Service Distribution Overview
&lt;/h2&gt;
&lt;h3&gt;
	Proxmox VM srv-prod-01
&lt;/h3&gt;
&lt;table&gt;
	&lt;thead&gt;
		&lt;tr&gt;
			&lt;th&gt;
				Service
			&lt;/th&gt;
			&lt;th&gt;
				Description
			&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;
				ArchiveBox
			&lt;/td&gt;
			&lt;td&gt;
				Bookmark Archival
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Audiobookshelf
			&lt;/td&gt;
			&lt;td&gt;
				Audiobook Management
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Calibre
			&lt;/td&gt;
			&lt;td&gt;
				EBook Management
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Dozzle
			&lt;/td&gt;
			&lt;td&gt;
				Logs Monitoring
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Homeassistant
			&lt;/td&gt;
			&lt;td&gt;
				Homeautomation, HomeKit Bridge
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Homepage
			&lt;/td&gt;
			&lt;td&gt;
				Home Dashboard
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Immich
			&lt;/td&gt;
			&lt;td&gt;
				Photo Library
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Jellyfin
			&lt;/td&gt;
			&lt;td&gt;
				Media Server
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Komodo
			&lt;/td&gt;
			&lt;td&gt;
				Docker Management
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Komodo Periphery
			&lt;/td&gt;
			&lt;td&gt;
				Docker Management Agent
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Komodo ntfy
			&lt;/td&gt;
			&lt;td&gt;
				Alerter Bridge
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Libation
			&lt;/td&gt;
			&lt;td&gt;
				Audibook Downloader
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Mealie
			&lt;/td&gt;
			&lt;td&gt;
				Recipe Management
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				MeTube
			&lt;/td&gt;
			&lt;td&gt;
				Video &amp; Audio Downloader
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Miniflux
			&lt;/td&gt;
			&lt;td&gt;
				RSS
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				ntfy
			&lt;/td&gt;
			&lt;td&gt;
				Push Service
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Paperless
			&lt;/td&gt;
			&lt;td&gt;
				Document Management
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Penpot
			&lt;/td&gt;
			&lt;td&gt;
				Design Tool
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				SABnzbd
			&lt;/td&gt;
			&lt;td&gt;
				Usenet Downloader
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Traefik
			&lt;/td&gt;
			&lt;td&gt;
				Reverse Proxy, SSL, etc.
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Tubesync
			&lt;/td&gt;
			&lt;td&gt;
				Video &amp; Audio Downloader
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Uptime Kuma
			&lt;/td&gt;
			&lt;td&gt;
				Monitoring
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Vaultwarden
			&lt;/td&gt;
			&lt;td&gt;
				Password Management
			&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;
	RPI DNS01
&lt;/h3&gt;
&lt;table&gt;
	&lt;thead&gt;
		&lt;tr&gt;
			&lt;th&gt;
				Service
			&lt;/th&gt;
			&lt;th&gt;
				Description
			&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Adguard Home
			&lt;/td&gt;
			&lt;td&gt;
				DNS Server
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Adguard Home Sync
			&lt;/td&gt;
			&lt;td&gt;
				Adguard Home Config Sync
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Dozzle Agent
			&lt;/td&gt;
			&lt;td&gt;
				Logs Agent
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Komodo Periphery
			&lt;/td&gt;
			&lt;td&gt;
				Docker Management Agent
			&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;
	RPI DNS02
&lt;/h3&gt;
&lt;table&gt;
	&lt;thead&gt;
		&lt;tr&gt;
			&lt;th&gt;
				Service
			&lt;/th&gt;
			&lt;th&gt;
				Description
			&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Adguard Home
			&lt;/td&gt;
			&lt;td&gt;
				DNS Server
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Dozzle Agent
			&lt;/td&gt;
			&lt;td&gt;
				Logs Agent
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Komodo Periphery
			&lt;/td&gt;
			&lt;td&gt;
				Docker Management Agent
			&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;
	All service configurations are stored in Git, updated automatically by Renovate, and redeployed via Komodo when changes are merged. We will look at the automation bit in part 2 and the deployed services in part 3 of this blog post series.
&lt;/p&gt;
&lt;p&gt;
	This setup balances critical services (DNS) across two Pis for resilience, while keeping heavier services (media, apps) centralized on the Ubuntu VM.
&lt;/p&gt;
&lt;h2&gt;
	Local DNS with Adguard Home
&lt;/h2&gt;
&lt;p&gt;
	AdGuard Home is my go-to solution for local DNS with ad and tracker blocking. I run two independent instances — one on each Pi — to ensure redundancy.
&lt;/p&gt;
&lt;p&gt;
	Why two instances?
&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;
		&lt;p&gt;
			Ensures DNS still works if one Pi reboots or fails
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Provides distributed DNS for clients across VLANs
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Enables load distribution and fault tolerance
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
	To keep their configs in sync, I run &lt;a href=&quot;https://github.com/bakito/adguardhome-sync&quot;&gt;adguardhome-sync&lt;/a&gt; on dns01:
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;services:
  adguardhome-sync:
    image: lscr.io/linuxserver/adguardhome-sync:v0.7.6-ls138@sha256:21b0311d8e0aecca093f6aa0c15a91e293de108d86477da768816eb75af130bb
    container_name: adguardhome-sync
    environment:
      - PUID=${PUID}
      - PGID=${PGID}
      - TZ=${TZ:-UTC}
    volumes:
      - ${VOLUME_PATH}/config:/config
    ports:
      - 8090:8080
    restart: unless-stopped
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;p&gt;
	The mounted config file then adds dns02 as a sync target. This way every change I make on dns01 will automatically be reflected on dns02 as well.
&lt;/p&gt;
&lt;div class=&quot;image&quot;&gt;
	&lt;img alt=&quot;An image showing the adguard web UI.&quot; loading=&quot;lazy&quot; src=&quot;/img/building-a-homelab/adguard.png&quot; width=&quot;463.5&quot;/&gt;
&lt;/div&gt;
&lt;h2&gt;
	📈 Monitoring with Uptime Kuma
&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/louislam/uptime-kuma&quot;&gt;Uptime Kuma&lt;/a&gt; runs in a Docker container on the Ubuntu VM. It monitors:
&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;
		&lt;p&gt;
			My public WireGuard endpoint
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			All internal apps via their Traefik routes / docker containers
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			DNS uptime on both Pi nodes
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			External services like GitHub and my VPS
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Cron Jobs and Backup Tasks
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
	It’s lightweight, supports alerting, and even shows response time history.
&lt;/p&gt;
&lt;div class=&quot;image&quot;&gt;
	&lt;img alt=&quot;An image showing the uptime-kuma web UI.&quot; loading=&quot;lazy&quot; src=&quot;/img/building-a-homelab/uptime-kuma.png&quot; width=&quot;463.5&quot;/&gt;
&lt;/div&gt;
&lt;h2&gt;
	📚 Logging with Dozzle
&lt;/h2&gt;
&lt;p&gt;
	Each of my Raspberry Pis runs a Dozzle agent, which streams container logs to the central Dozzle instance. Log files written to disk are available through a seperate output stream I create. This gives me:
&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;
		&lt;p&gt;
			One place to view logs from every device
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Live log tailing via browser
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Easy debugging if something breaks
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
	On the central VM, I run the Dozzle web UI and configure it to connect to the remote agents or output streams:
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;dozzle:
    image: amir20/dozzle:v8.12.20@sha256:6e3c64615e15493dbd2a476650d17b1b0038ba7dbd3cfe1a611df64ed57e602a
    container_name: dozzle
    security_opt:
      - no-new-privileges:true
    restart: unless-stopped
    networks:
      - internal
      - proxy
    environment:
      - DOZZLE_LEVEL=${DOZZLE_LEVEL}
      - DOZZLE_ENABLE_ACTIONS=${DOZZLE_ENABLE_ACTIONS}
      - DOZZLE_ENABLE_SHELL=${DOZZLE_ENABLE_SHELL}
      - DOZZLE_NO_ANALYTICS=${DOZZLE_NO_ANALYTICS}
      - DOZZLE_FILTER=${DOZZLE_FILTER}
      - DOZZLE_AUTH_PROVIDER=${DOZZLE_AUTH_PROVIDER}
      - DOZZLE_HOSTNAME=${DOZZLE_HOSTNAME}
      - DOZZLE_REMOTE_AGENT=${DOZZLE_REMOTE_AGENT}
    volumes:
      - ${VOLUME_PATH}/data:/data
      - ${VOLUME_PATH}/certs:/certs
      - /var/run/docker.sock:/var/run/docker.sock
    labels:
      - &amp;quot;traefik.enable=true&amp;quot;
      - &amp;quot;traefik.http.routers.dozzle.rule=Host(`mydomain.de`)&amp;quot;
      - &amp;quot;traefik.http.routers.dozzle.entrypoints=https&amp;quot;
      - &amp;quot;traefik.http.routers.dozzle.tls=true&amp;quot;
      - &amp;quot;traefik.http.services.dozzle.loadbalancer.server.port=8080&amp;quot;
      - &amp;quot;traefik.docker.network=proxy&amp;quot;

  # example of an output stream
  dozzle-traefik:
    container_name: dozzle-traefik
    image: alpine@sha256:6662067ba6f090f8a2c8b5b50309692be03bffef2729b453425edd4f26343377
    volumes:
      - ${TRAEFIK_LOG}:/var/log/stream.log
    command:
      - tail
      - -f
      - /var/log/stream.log
    network_mode: none
    restart: unless-stopped
    labels:
      - dev.dozzle.group=traefik
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;div class=&quot;image&quot;&gt;
	&lt;img alt=&quot;An image showing the dozzle web UI.&quot; loading=&quot;lazy&quot; src=&quot;/img/building-a-homelab/dozzle.png&quot; width=&quot;463.5&quot;/&gt;
&lt;/div&gt;
&lt;h2&gt;
	🛜 Traefik: The Ingress Brain
&lt;/h2&gt;
&lt;p&gt;
	Every internal service is routed through Traefik, my reverse proxy of choice. Key features in my setup:
&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;
		&lt;p&gt;
			Automatic TLS via Let&apos;s Encrypt
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Internal-only DNS resolution (e.g., mydomain.de)
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Container labels define routing rules declaratively
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
	In Adguard Home i added &lt;code&gt;Custom DNS Rewrite&lt;/code&gt; rule. Whenever my DNS server gets a request to resolve the IP address for &lt;code&gt;*.mydomain.de&lt;/code&gt; it points to my traefik instance which then routes based on the host name to the actual docker containers or machines. Since traefik comes certbot/acme out of the box I can use my own domain to SSL encrypt this connection with a certificate requested from Let&apos;s Encrypt. To set things up I mostly followed this tutorial here so I won&apos;t go into detail: &lt;a href=&quot;https://technotim.live/posts/traefik-3-docker-certificates/&quot;&gt;Traefik Tutorial&lt;/a&gt;.
&lt;/p&gt;
&lt;h2&gt;
	➡️ Conclusion
&lt;/h2&gt;
&lt;p&gt;
	Once you feel the excitement and joy of deploying actually useful apps to your homelab there is no step back. Watching a movie on Jellyfin, reading my RSS feeds through Miniflux, storing passwords in my own, private vaultwarden instance just feels very rewarding. On top I can access these services via my own custom domain SSL encrypted, although I do not expose them to the internet. In the next part we have a closer look at my network setup and how I stepped up my game here.
&lt;/p&gt;
		</content>
	</entry>
	<entry>
		<title type="text">Building a homelab (2/5): Renovate and Komodo for Auto Deployments (GitOps)</title>
		<id>https://davidvonk.dev/homelab/building-a-homelab-2-5-gitops-renovate-and-komodo-for-auto-deployments</id>
		<link href="https://davidvonk.dev/homelab/building-a-homelab-2-5-gitops-renovate-and-komodo-for-auto-deployments" rel="alternate">
		</link>
		<updated>2025-06-04T15:15:00Z</updated>
		<summary type="text">
			A blog post series about my journey building a homelab
		</summary>
		<content type="html">
			&lt;blockquote&gt;
	&lt;p&gt;
		If it is not in git it doesn&apos;t exist.
	&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;
	Keeping containers updated in a homelab can quickly become a chore — especially when you’re managing multiple services, distributed across devices, and sensitive to downtime. That’s why I adopted a GitOps workflow using &lt;a href=&quot;https://github.com/renovatebot/renovate&quot;&gt;Renovate&lt;/a&gt; for updates and &lt;a href=&quot;https://komo.do&quot;&gt;Komodo&lt;/a&gt; to orchestrate my Docker Compose deployments.
&lt;/p&gt;
&lt;p&gt;
	This post will walk you through how I’ve set that up: from repo layout to cron jobs to automatic deployments across my Pi nodes and main VM.
&lt;/p&gt;
&lt;h2&gt;
	🛠️ Repo Structure
&lt;/h2&gt;
&lt;p&gt;
	I manage everything via a single GitHub repository that acts as the source of truth for my homelab. Here’s a simplified structure:
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-&quot;&gt;.
├── README.md
├── containers
│   ├── dns01
│   ├── dns02
│   └── srv-prod-01
├── docs
│   ├── attachments
│   ├── docker
│   ├── machines
│   ├── misc
│   ├── network
│   ├── services
│   └── tasks
├── dotfiles
│   ├── bash_aliases
│   └── gitconfig
├── komodo.toml
├── renovate.json
├── scripts
│   └── update-komodo.sh
└── tasks
    ├── deprecated
    ├── docker-cleanup
    ├── dsm-config-backup
    ├── github-backup
    ├── ip-backup
    ├── monitor-remote-backup
    ├── renovate
    ├── rss-backup
    └── vps
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;p&gt;
	Each stack has its own compose.yaml and optionally an .env file. This allows me to keep configurations isolated per node and have Komodo pick them up automatically.
	
	The whole Komodo configuration is also stored in this repository (komodo.toml). This allows me to even create new docker-compose projects just by pushing to the git repository.
&lt;/p&gt;
&lt;h2&gt;
	🔄 Automated Updates with Renovate
&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/renovatebot/renovate&quot;&gt;Renovate&lt;/a&gt; is a powerful dependency updater that I run on a schedule via cron. It scans all Docker Compose files and automatically:
&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;
		&lt;p&gt;
			Detects outdated images
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Creates pull requests with version bumps
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Groups updates if desired (e.g., all linuxserver.io containers)
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
	To set this up I added a renovate.json in the root of my repository:
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-json&quot;&gt;{
  &amp;quot;$schema&amp;quot;: &amp;quot;https://docs.renovatebot.com/renovate-schema.json&amp;quot;,
  &amp;quot;extends&amp;quot;: [
    &amp;quot;config:recommended&amp;quot;,
    &amp;quot;docker:pinDigests&amp;quot;,
    &amp;quot;docker:enableMajor&amp;quot;
  ],
  &amp;quot;labels&amp;quot;: [
    &amp;quot;renovate&amp;quot;
  ],
  &amp;quot;dependencyDashboard&amp;quot;: true,
  &amp;quot;ignoreTests&amp;quot;: true,
  &amp;quot;enabledManagers&amp;quot;: [
    &amp;quot;docker-compose&amp;quot;,
    &amp;quot;pip_requirements&amp;quot;,
    &amp;quot;custom.regex&amp;quot;
  ],
  &amp;quot;customManagers&amp;quot;: [
    {
      &amp;quot;customType&amp;quot;: &amp;quot;regex&amp;quot;,
      &amp;quot;managerFilePatterns&amp;quot;: [
        &amp;quot;/^tasks/renovate/entrypoint\\.sh$/&amp;quot;
      ],
      &amp;quot;matchStrings&amp;quot;: [
	&amp;quot;RENOVATE_VERSION=\&amp;quot;(?&amp;lt;currentValue&amp;gt;.*?)(?:@(?&amp;lt;currentDigest&amp;gt;sha256:[a-f0-9]+))?\&amp;quot;&amp;quot;
      ],
      &amp;quot;depNameTemplate&amp;quot;: &amp;quot;renovate/renovate&amp;quot;,
      &amp;quot;autoReplaceStringTemplate&amp;quot;: &amp;quot;RENOVATE_VERSION=\&amp;quot;{{{newValue}}}@{{{newDigest}}}\&amp;quot;&amp;quot;,
      &amp;quot;datasourceTemplate&amp;quot;: &amp;quot;docker&amp;quot;
    }
  ],
  &amp;quot;docker-compose&amp;quot;: {
    &amp;quot;managerFilePatterns&amp;quot;: [
      &amp;quot;/(^|/)(?:docker-)?compose[^/]*\\.ya?ml(?:.j2)?$/&amp;quot;
    ]
  },
  &amp;quot;packageRules&amp;quot;: [
    {
      &amp;quot;matchDatasources&amp;quot;: [&amp;quot;docker&amp;quot;],
      &amp;quot;matchUpdateTypes&amp;quot;: [&amp;quot;digest&amp;quot;],
      &amp;quot;enabled&amp;quot;: false
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;p&gt;
	I then added a new cronjob on my main server to trigger the renovatebot every 30 minutes:
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-&quot;&gt;*/30 * * * * root /opt/repos/homelab/tasks/renovate/entrypoint.sh &amp;gt;&amp;gt; /mnt/data/Logs/tasks/renovate.log 2&amp;gt;&amp;amp;1
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;p&gt;
	The entrypoint.sh script triggers the renovatebot via docker:
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;RENOVATE_VERSION=&amp;quot;40.40.1@sha256:ef85bf681b6a94e1a2a8afdcdeff8caa2fb92d7926538657671e8118ea03dffd&amp;quot;

docker run --rm \
  --env-file &amp;quot;${ENV_FILE}&amp;quot; \
  -v &amp;quot;${CONFIG_JS_FILE}:/usr/src/app/config.js&amp;quot; \
  &amp;quot;renovate/renovate:${RENOVATE_VERSION}&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;p&gt;
	This ultimately results in Pull Requests like the following:
&lt;/p&gt;
&lt;div class=&quot;image&quot;&gt;
	&lt;img alt=&quot;An image showing a pull request a renovate bot added to a GitHub repository.&quot; loading=&quot;lazy&quot; src=&quot;/img/building-a-homelab/renovate-pull-request.png&quot; width=&quot;463.5&quot;/&gt;
&lt;/div&gt;
&lt;p&gt;
	When I merge one of these PRs, it triggers Komodo to redeploy only the affected stack — no need for a full redeploy or even SSHing into anything.
&lt;/p&gt;
&lt;h2&gt;
	🦖 Komodo: Deploying to the Edge
&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://komo.do&quot;&gt;Komodo&lt;/a&gt; is the core deployment engine. Think of it like a minimal orchestrator for docker-compose, but smarter and Git-aware.
&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;
		&lt;p&gt;
			The central agent runs on the Ubuntu VM
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			The periphery agents run on my Raspberry Pis
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			All agents receive their stack definitions from the GitHub repo
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
	When a PR is merged and the repository is synced, Komodo checks which stacks changed and selectively redeploys them on the right nodes.
&lt;/p&gt;
&lt;h3&gt;
	How it knows what to redeploy:
&lt;/h3&gt;
&lt;ul&gt;
	&lt;li&gt;
		&lt;p&gt;
			Each stack is tagged with a deployment target (e.g., pi-dns1, core, etc.)
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Komodo watches the main branch and computes diffs
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Changed Compose files → redeploy those stacks only
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
	Komodo is setup via systemd or docker compose. I opted for the docker compose approach.
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;services:
  mongo:
    image: mongo:8.0.9@sha256:3e8fd506d185ea100867c9da5f90414cee744d1545449038c60190f3fd3cc274
    container_name: komodo-mongo-db
    labels:
      komodo.skip: # Prevent Komodo from stopping with StopAllContainers
    command: --quiet --wiredTigerCacheSizeGB 0.25
    restart: unless-stopped
    volumes:
      - ${MONGO_DATA_PATH}:/data/db
      - ${MONGO_CONFIG_PATH}:/data/configdb
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${KOMODO_DB_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${KOMODO_DB_PASSWORD}
    networks:
      - internal
  
  core:
    image: ghcr.io/moghtech/komodo-core:1.18.0@sha256:b65ee6d2af592841e610aee19951995ac89fd2046db451b77ccbf82506f19f41
    container_name: komodo
    restart: unless-stopped
    depends_on:
      - mongo
    env_file: ./.env
    environment:
      KOMODO_DATABASE_ADDRESS: mongo:27017
      KOMODO_DATABASE_USERNAME: ${KOMODO_DB_USERNAME}
      KOMODO_DATABASE_PASSWORD: ${KOMODO_DB_PASSWORD}
    networks:
      - proxy
      - internal
      - periphery
    labels:
      - &amp;quot;komodo.skip=true&amp;quot; # Prevent Komodo from stopping with StopAllContainers
      - &amp;quot;traefik.enable=true&amp;quot;
      - &amp;quot;traefik.http.routers.komodo.rule=Host(`mydomain.de`)&amp;quot;
      - &amp;quot;traefik.http.routers.komodo.entrypoints=https&amp;quot;
      - &amp;quot;traefik.http.routers.komodo.tls=true&amp;quot;
      - &amp;quot;traefik.http.services.komodo.loadbalancer.server.port=9120&amp;quot;
      - &amp;quot;traefik.docker.network=proxy&amp;quot;
    volumes:
      - ${REPO_CACHE_PATH}:/repo-cache

  komodo-ntfy:
    image: foxxmd/komodo-ntfy-alerter:0.0.8@sha256:df8dc93c22c23092c9e19c1b4581c30a04be125f8cfee57cd8537b8abbdb5b16
    container_name: komodo-ntfy
    restart: unless-stopped
    env_file:
      - ./.env
    networks:
      - internal
    ports:
      - &amp;quot;7000:7000&amp;quot;

networks:
  proxy:
    external: true
  periphery:
    external: true
  internal:
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;p&gt;
	On all machines runs a periphery agent to connect those servers to the core komodo instance:
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;services:
  periphery:
    image: ghcr.io/moghtech/komodo-periphery:1.18.0@sha256:fb12dd26fcb964ac95c0c669cca6efd4dc8c9e3a147f7873835f23727058292f
    container_name: periphery
    labels:
      komodo.skip: # Prevent Komodo from stopping with StopAllContainers
    restart: unless-stopped
    env_file: ./.env
    networks:
      - periphery
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /proc:/proc
      - ${PERIPHERY_ROOT_DIRECTORY:-/etc/komodo}:${PERIPHERY_ROOT_DIRECTORY:-/etc/komodo}
      - ${PERIPHERY_REPO_DIR:-/etc/komodo/repos}:${PERIPHERY_REPO_DIR:-/etc/komodo/repos}

networks:
  periphery:
    external: true
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;p&gt;
	I then configured the Komodo instance through the UI. I added a Resource Sync to automatically sync changes made in the Komodo UI to my GitHub repository. Next I added alerters (via ntfy) to get notifications whenever an interesting update happens through Komodo. I also added my GitHub repository and my docker compose stacks to Komodo. Last but not least I added a procedure to run hourly to check for updates in the GitHub repository and redeploy any changed stacks. Here is the configuration for this specific action:
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-toml&quot;&gt;[[procedure]]
name = &amp;quot;pull-and-deploy&amp;quot;
description = &amp;quot;Pulls stack-repo, deploys stacks&amp;quot;
config.schedule = &amp;quot;0 0 * * * *&amp;quot;
config.schedule_format = &amp;quot;Cron&amp;quot;

[[procedure.config.stage]]
name = &amp;quot;Pull Repo&amp;quot;
enabled = true
executions = [
  { execution.type = &amp;quot;PullRepo&amp;quot;, execution.params.repo = &amp;quot;homelab&amp;quot;, enabled = true }
]

[[procedure.config.stage]]
name = &amp;quot;Update Stacks&amp;quot;
enabled = true
executions = [
  { execution.type = &amp;quot;BatchDeployStackIfChanged&amp;quot;, execution.params.pattern = &amp;quot;*&amp;quot;, enabled = true }
]

[[procedure.config.stage]]
name = &amp;quot;Prune System&amp;quot;
enabled = true
executions = [
  { execution.type = &amp;quot;PruneSystem&amp;quot;, execution.params.server = &amp;quot;dns01&amp;quot;, enabled = true },
  { execution.type = &amp;quot;PruneSystem&amp;quot;, execution.params.server = &amp;quot;dns02&amp;quot;, enabled = true },
  { execution.type = &amp;quot;PruneSystem&amp;quot;, execution.params.server = &amp;quot;srv-prod-01&amp;quot;, enabled = true }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;div class=&quot;image&quot;&gt;
	&lt;img alt=&quot;An image showing the Komodo web UI.&quot; loading=&quot;lazy&quot; src=&quot;/img/building-a-homelab/komodo.png&quot; width=&quot;463.5&quot;/&gt;
&lt;/div&gt;
&lt;h2&gt;
	🔁 The Full Update Lifecycle
&lt;/h2&gt;
&lt;ol&gt;
	&lt;li&gt;
		&lt;p&gt;
			Renovate runs via cron and checks for new image tags
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			It creates a PR in GitHub with the updated image version
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			I review and merge the PR
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Komodo pulls the updated config
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			It calculates diffs and triggers a targeted redeploy
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			The updated service is rebuilt and restarted
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
	Zero manual SSH needed. Logs and container status can be checked in Dozzle from any machine (more on that in a later part).
&lt;/p&gt;
&lt;h2&gt;
	✅ Why This Works So Well
&lt;/h2&gt;
&lt;ul&gt;
	&lt;li&gt;
		&lt;p&gt;
			Idempotency: The same inputs always yield the same stack state
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Minimal intervention: I only merge PRs, the rest is automated
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Fast rollback: Revert a commit → auto rollback
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Clear audit trail: Everything is version-controlled in Git
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;
	🔜 Up Next: Services That Power the Homelab
&lt;/h2&gt;
&lt;p&gt;
	In the next post, I’ll break down the actual containers I run, how they’re distributed across machines, and how I handle DNS, logging, and synchronization (like AdGuardHome Sync across two Pis).
&lt;/p&gt;
		</content>
	</entry>
	<entry>
		<title type="text">Building a homelab (1/5): The big picture</title>
		<id>https://davidvonk.dev/homelab/building-a-homelab-1-5-the-big-picture</id>
		<link href="https://davidvonk.dev/homelab/building-a-homelab-1-5-the-big-picture" rel="alternate">
		</link>
		<updated>2025-06-04T14:15:00Z</updated>
		<summary type="text">
			A blog post series about my journey building a homelab
		</summary>
		<content type="html">
			&lt;blockquote&gt;
	&lt;p&gt;
		Home is where your lab is.
	&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;
	I’ve always been fascinated by infrastructure — how services run behind the scenes, how networks talk to each other, and how automation can bring order to chaos. That’s what led me to build and maintain a fully self-hosted homelab, not just for tinkering, but for actual day-to-day use.
&lt;/p&gt;
&lt;p&gt;
	This blog series walks you through every part of my homelab — from the nuts and bolts of the network stack to the GitOps pipeline that drives automated updates and deployment.
&lt;/p&gt;
&lt;h2&gt;
	❓ Why I Built This
&lt;/h2&gt;
&lt;p&gt;
	Like many who run homelabs, my goals were:
&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;
		&lt;p&gt;
			Learning by doing (networking, infrastructure-as-code, automation)
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Host my own services (newsreader, media, monitoring, DNS, etc.)
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Improve privacy and control over my own data
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Build a resilient, automated, low-touch system
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
	Over time, it’s grown into a robust, self-sufficient ecosystem that closely mimics professional infrastructure, just at a smaller scale.
&lt;/p&gt;
&lt;h2&gt;
	💻 Hardware Overview
&lt;/h2&gt;
&lt;table&gt;
	&lt;thead&gt;
		&lt;tr&gt;
			&lt;th&gt;
				Device
			&lt;/th&gt;
			&lt;th&gt;
				Role
			&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Draytek Vigor 167
			&lt;/td&gt;
			&lt;td&gt;
				DSL Modem
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				UniFi Express 7
			&lt;/td&gt;
			&lt;td&gt;
				Router
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				UniFi Pro Max 16 Switch
			&lt;/td&gt;
			&lt;td&gt;
				Switch
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				U7 Pro Wall, U7 Lite (2x)
			&lt;/td&gt;
			&lt;td&gt;
				Access Points
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				FritzBox 7490
			&lt;/td&gt;
			&lt;td&gt;
				DECT Telephone Base Station
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				RPI 3 Model B
			&lt;/td&gt;
			&lt;td&gt;
				DNS 01
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				RPI 3 Model B+
			&lt;/td&gt;
			&lt;td&gt;
				DNS 02 Failover
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				GMKTEC Nucbox M5 Plus Mini PC
			&lt;/td&gt;
			&lt;td&gt;
				Proxmox Host
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Main NAS
			&lt;/td&gt;
			&lt;td&gt;
				Synology DS923+
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Backup NAS
			&lt;/td&gt;
			&lt;td&gt;
				Synology DS918
			&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;
	🛜 Networking Layout
&lt;/h2&gt;
&lt;ul&gt;
	&lt;li&gt;
		&lt;p&gt;
			VLANs segment my devices by function (e.g., IOT, guests, infrastructure, work)
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Multiple SSIDs are broadcasted for each VLAN through UniFi APs
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			All cabling in the house runs to the central UniFi switch
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Internet comes in via PPPoE through a DSL modem
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
	This physical setup gives me both strong performance and clean network segmentation.
	
	Also once fiber optics will finally be available in our home I&apos;ll be able to just switch out the DSL Modem and the network should function exactly the same. We will have a closer look at the networking infrastructure in part 4 of this series.
&lt;/p&gt;
&lt;h2&gt;
	📱 Core Services
&lt;/h2&gt;
&lt;p&gt;
	Most of my services run in Docker and are deployed via Komodo:
&lt;/p&gt;
&lt;h3&gt;
	Proxmox VM srv-prod-01
&lt;/h3&gt;
&lt;table&gt;
	&lt;thead&gt;
		&lt;tr&gt;
			&lt;th&gt;
				Service
			&lt;/th&gt;
			&lt;th&gt;
				Description
			&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;
				ArchiveBox
			&lt;/td&gt;
			&lt;td&gt;
				Bookmark Archival
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Audiobookshelf
			&lt;/td&gt;
			&lt;td&gt;
				Audiobook Management
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Calibre
			&lt;/td&gt;
			&lt;td&gt;
				EBook Management
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Dozzle
			&lt;/td&gt;
			&lt;td&gt;
				Logs Monitoring
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Homeassistant
			&lt;/td&gt;
			&lt;td&gt;
				Homeautomation, HomeKit Bridge
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Homepage
			&lt;/td&gt;
			&lt;td&gt;
				Home Dashboard
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Immich
			&lt;/td&gt;
			&lt;td&gt;
				Photo Library
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Jellyfin
			&lt;/td&gt;
			&lt;td&gt;
				Media Server
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Komodo
			&lt;/td&gt;
			&lt;td&gt;
				Docker Management
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Komodo Periphery
			&lt;/td&gt;
			&lt;td&gt;
				Docker Management Agent
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Komodo ntfy
			&lt;/td&gt;
			&lt;td&gt;
				Alerter Bridge
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Libation
			&lt;/td&gt;
			&lt;td&gt;
				Audibook Downloader
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Mealie
			&lt;/td&gt;
			&lt;td&gt;
				Recipe Management
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				MeTube
			&lt;/td&gt;
			&lt;td&gt;
				Video &amp; Audio Downloader
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Miniflux
			&lt;/td&gt;
			&lt;td&gt;
				RSS
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				ntfy
			&lt;/td&gt;
			&lt;td&gt;
				Push Service
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Paperless
			&lt;/td&gt;
			&lt;td&gt;
				Document Management
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Penpot
			&lt;/td&gt;
			&lt;td&gt;
				Design Tool
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				SABnzbd
			&lt;/td&gt;
			&lt;td&gt;
				Usenet Downloader
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Traefik
			&lt;/td&gt;
			&lt;td&gt;
				Reverse Proxy, SSL, etc.
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Tubesync
			&lt;/td&gt;
			&lt;td&gt;
				Video &amp; Audio Downloader
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Uptime Kuma
			&lt;/td&gt;
			&lt;td&gt;
				Monitoring
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Vaultwarden
			&lt;/td&gt;
			&lt;td&gt;
				Password Management
			&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;
	RPI DNS01
&lt;/h3&gt;
&lt;table&gt;
	&lt;thead&gt;
		&lt;tr&gt;
			&lt;th&gt;
				Service
			&lt;/th&gt;
			&lt;th&gt;
				Description
			&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Adguard Home
			&lt;/td&gt;
			&lt;td&gt;
				DNS Server
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Adguard Home Sync
			&lt;/td&gt;
			&lt;td&gt;
				Adguard Home Config Sync
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Dozzle Agent
			&lt;/td&gt;
			&lt;td&gt;
				Logs Agent
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Komodo Periphery
			&lt;/td&gt;
			&lt;td&gt;
				Docker Management Agent
			&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;
	RPI DNS02
&lt;/h3&gt;
&lt;table&gt;
	&lt;thead&gt;
		&lt;tr&gt;
			&lt;th&gt;
				Service
			&lt;/th&gt;
			&lt;th&gt;
				Description
			&lt;/th&gt;
		&lt;/tr&gt;
	&lt;/thead&gt;
	&lt;tbody&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Adguard Home
			&lt;/td&gt;
			&lt;td&gt;
				DNS Server
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Dozzle Agent
			&lt;/td&gt;
			&lt;td&gt;
				Logs Agent
			&lt;/td&gt;
		&lt;/tr&gt;
		&lt;tr&gt;
			&lt;td&gt;
				Komodo Periphery
			&lt;/td&gt;
			&lt;td&gt;
				Docker Management Agent
			&lt;/td&gt;
		&lt;/tr&gt;
	&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;
	All service configurations are stored in Git, updated automatically by Renovate, and redeployed via Komodo when changes are merged. We will look at the automation bit in part 2 and the deployed services in part 3 of this blog post series.
&lt;/p&gt;
&lt;h2&gt;
	🔐 Secure Remote Access
&lt;/h2&gt;
&lt;p&gt;
	For secure external access, I run a WireGuard VPN through a VPS with a static IPv4 address. This lets me:
&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;
		&lt;p&gt;
			Connect back home from anywhere
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Route selected traffic over WireGuard
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Secure inbound services without exposing ports directly
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
	I will detail the setup in part 4 when we have a look at the overall networking infrastructure.
&lt;/p&gt;
&lt;p&gt;
	We will also look at other deployed mechanism to harden the overall security of my homelab in the final part of this series, f.e. securing SSH access to my machines.
&lt;/p&gt;
		</content>
	</entry>
	<entry>
		<title type="text">Writing a chess app (9/9): Testing and Conclusion</title>
		<id>https://davidvonk.dev/swift/writing-a-chess-app-9-9-testing-and-conclusion</id>
		<link href="https://davidvonk.dev/swift/writing-a-chess-app-9-9-testing-and-conclusion" rel="alternate">
		</link>
		<updated>2024-10-31T17:52:00Z</updated>
		<summary type="text">
			A blog post series detailing my journey of developing a chess app for iOS and macOS
		</summary>
		<content type="html">
			&lt;h2&gt;
	Unit Tests
&lt;/h2&gt;
&lt;p&gt;
	Well you probably think now &quot;Isn&apos;t this a personal project? Why bother writing unit tests?&quot; I actually found a lot of joy writing unit tests for this project. Since I basically have no third-party dependencies, no network traffic, etc. there isn&apos;t really much to mock or stub. The unit tests do what they are best at: Testing a logical unit of code and making sure it behaves the way it should. With the unit tests in place I feel very confident to refactor and iterate on the various implemented algorithms and logic. I actually found that for the PGN parser and chess logic packages test driven development was quite fun and helpful in making my implementation correct. For the future I plan to have a look at the new&lt;a href=&quot;https://developer.apple.com/xcode/swift-testing/&quot;&gt; swift-testing&lt;/a&gt; framework.
&lt;/p&gt;
&lt;h2&gt;
	That&apos;s a wrap
&lt;/h2&gt;
&lt;p&gt;
	You probably already got the impression that I am pretty passionate about chess and software development. This project really helped me finding joy again in writing software for my own personal use. What I especially liked about this project is that it was totally different from my typical &quot;side project&quot;. Most of the time I repeat the same boilerplate code, requesting some API endpoints and displaying data in some form of a list. This time it was and still is all about performance, reading up on algorithms, creating some custom UI components. So I couldn&apos;t be happier I pulled through this time and can actually hold a useful product in my hands which I am very keen to iterate on in the upcoming months.
&lt;/p&gt;
&lt;p&gt;
	Despite all the positive experiences with this project there is one downside I found rather funny:  I am spending more time in Xcode and less time on &lt;a href=&quot;https://lichess.org&quot;&gt;lichess&lt;/a&gt; (Lichess is a charity and a free, libre, no-ads, open source chess server) actually playing chess. I guess there is only a limited amount of time in a day but I am looking forward to getting back at improving my chess skills now with my own little chess companion in my pocket.
&lt;/p&gt;
&lt;p&gt;
	If you liked this article, want to talk about chess or software development let me know!
&lt;/p&gt;
		</content>
	</entry>
	<entry>
		<title type="text">Writing a chess app (8/9): Using a chess engine locally</title>
		<id>https://davidvonk.dev/swift/writing-a-chess-app-8-9-using-a-chess-engine-locally</id>
		<link href="https://davidvonk.dev/swift/writing-a-chess-app-8-9-using-a-chess-engine-locally" rel="alternate">
		</link>
		<updated>2024-10-31T16:52:00Z</updated>
		<summary type="text">
			A blog post series detailing my journey of developing a chess app for iOS and macOS
		</summary>
		<content type="html">
			&lt;h2&gt;
	Available engines
&lt;/h2&gt;
&lt;p&gt;
	When developing a chess application, you have several options for integrating a chess engine. The two most popular choices are: &lt;a href=&quot;https://stockfishchess.org&quot;&gt;Stockfish&lt;/a&gt; and &lt;a href=&quot;https://lczero.org&quot;&gt;Leela Chess Zero&lt;/a&gt;. Both engines are open source, extremly powerful and support the UCI engine protocol. For my project I chose to use Stockfish as it used by my favorite chess platform lichess and besides that considered as the best chess engine currently existing in terms of playing strength.
&lt;/p&gt;
&lt;h2&gt;
	UCI Engine Protocol
&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://backscattering.de/chess/uci/2006-04.txt&quot;&gt;UCI protocol documentation&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
	The Universal Chess Interface (UCI) is a protocol that allows communication between chess engines and GUIs. It standardizes the way commands are sent and received, making it easier for us to integrate different engines into our applications.
&lt;/p&gt;
&lt;h3&gt;
	UCI Command Structure
&lt;/h3&gt;
&lt;p&gt;
	The UCI protocol consists of a series of text-based commands that the GUI sends to the engine, and responses that the engine sends back. Here’s a breakdown of some of the most common commands in the UCI protocol:
&lt;/p&gt;
&lt;h4&gt;
	1. Initialization Commands
&lt;/h4&gt;
&lt;ul&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;&lt;code&gt;uci&lt;/code&gt;&lt;/strong&gt;: This command is sent by the GUI to initiate communication with the engine. The engine responds with its identity and capabilities.
		&lt;/p&gt;
		&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;:
		&lt;/p&gt;
		&lt;figure class=&quot;highlight&quot;&gt;
			&lt;pre&gt;&lt;code class=&quot;language-&quot;&gt;&amp;gt; uci &amp;lt; id name Stockfish 15 &amp;lt; uciok
&lt;/code&gt;&lt;/pre&gt;
		&lt;/figure&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;&lt;code&gt;isready&lt;/code&gt;&lt;/strong&gt;: This command checks if the engine is ready to receive new commands. The engine responds with &lt;code&gt;readyok&lt;/code&gt; when it is ready.
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;
	2. Position Setup Commands
&lt;/h4&gt;
&lt;ul&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;&lt;code&gt;position&lt;/code&gt;&lt;/strong&gt;: This command sets the position on the board. It can take two forms:
		&lt;/p&gt;
		&lt;ul&gt;
			&lt;li&gt;
				&lt;p&gt;&lt;strong&gt;&lt;code&gt;position startpos&lt;/code&gt;&lt;/strong&gt;: Initializes the board to the standard starting position.
				&lt;/p&gt;
			&lt;/li&gt;
			&lt;li&gt;
				&lt;p&gt;&lt;strong&gt;&lt;code&gt;position fen &amp;lt;FEN&amp;gt;&lt;/code&gt;&lt;/strong&gt;: Sets the board to a specific configuration defined by the FEN string.
				&lt;/p&gt;
			&lt;/li&gt;
		&lt;/ul&gt;
		&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;:
		&lt;/p&gt;
		&lt;figure class=&quot;highlight&quot;&gt;
			&lt;pre&gt;&lt;code class=&quot;language-&quot;&gt;&amp;gt; position startpos
&lt;/code&gt;&lt;/pre&gt;
		&lt;/figure&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;&lt;code&gt;setposition&lt;/code&gt;&lt;/strong&gt;: Similar to &lt;code&gt;position&lt;/code&gt;, but used to set a position without the need to specify moves.
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;
	3. Move Calculation Commands
&lt;/h4&gt;
&lt;ul&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;&lt;code&gt;go&lt;/code&gt;&lt;/strong&gt;: This command instructs the engine to start calculating the best move. It can be accompanied by parameters such as:
		&lt;/p&gt;
		&lt;ul&gt;
			&lt;li&gt;
				&lt;p&gt;&lt;strong&gt;&lt;code&gt;depth &amp;lt;n&amp;gt;&lt;/code&gt;&lt;/strong&gt;: Limits the search to a specific depth.
				&lt;/p&gt;
			&lt;/li&gt;
			&lt;li&gt;
				&lt;p&gt;&lt;strong&gt;&lt;code&gt;time &amp;lt;milliseconds&amp;gt;&lt;/code&gt;&lt;/strong&gt;: Limits the time the engine can spend calculating.
				&lt;/p&gt;
			&lt;/li&gt;
			&lt;li&gt;
				&lt;p&gt;&lt;strong&gt;&lt;code&gt;movetime &amp;lt;milliseconds&amp;gt;&lt;/code&gt;&lt;/strong&gt;: Specifies the exact time to think for the current move.
				&lt;/p&gt;
			&lt;/li&gt;
		&lt;/ul&gt;
		&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;:
		&lt;/p&gt;
		&lt;figure class=&quot;highlight&quot;&gt;
			&lt;pre&gt;&lt;code class=&quot;language-&quot;&gt;&amp;gt; go movetime 2000
&lt;/code&gt;&lt;/pre&gt;
		&lt;/figure&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;&lt;code&gt;stop&lt;/code&gt;&lt;/strong&gt;: This command tells the engine to stop its calculations immediately. The engine will return the best move it has found so far.
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;
	4. Engine Options Commands
&lt;/h4&gt;
&lt;ul&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;&lt;code&gt;setoption name &amp;lt;name&amp;gt; value &amp;lt;value&amp;gt;&lt;/code&gt;&lt;/strong&gt;: This command allows the GUI to set various options for the engine, such as adjusting its playing style or tuning specific parameters.
		&lt;/p&gt;
		&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;:
		&lt;/p&gt;
		&lt;figure class=&quot;highlight&quot;&gt;
			&lt;pre&gt;&lt;code class=&quot;language-&quot;&gt;&amp;gt; setoption name Hash value 2048
&lt;/code&gt;&lt;/pre&gt;
		&lt;/figure&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;
	5. Termination Commands
&lt;/h4&gt;
&lt;ul&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;&lt;code&gt;quit&lt;/code&gt;&lt;/strong&gt;: This command is used to terminate the engine process. The engine will respond with a message indicating it is shutting down.
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;
	Example Interaction Flow
&lt;/h3&gt;
&lt;p&gt;
	To illustrate how UCI works in practice, let’s walk through a typical interaction between a GUI and a chess engine:
&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;Initialization&lt;/strong&gt;:
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-&quot;&gt;&amp;gt; uci &amp;lt; id name Stockfish 15 &amp;lt; uciok
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;ol&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;Setting Up the Position&lt;/strong&gt;:
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-&quot;&gt;&amp;gt; position startpos
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;ol&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;Instructing the Engine to Calculate a Move&lt;/strong&gt;:
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-&quot;&gt;&amp;gt; go movetime 3000
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;ol&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;Receiving the Best Move&lt;/strong&gt;:
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-&quot;&gt;&amp;lt; bestmove e2e4 &amp;lt; info depth 20 seldepth 30 score cp 25
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;ol&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;Stopping the Engine (if needed)&lt;/strong&gt;:
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-&quot;&gt;&amp;gt; stop &amp;lt; bestmove e2e4
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;ol&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;Terminating the Engine&lt;/strong&gt;:
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-&quot;&gt;&amp;gt; quit
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;h2&gt;
	Redirect STDOUT and STDIN
&lt;/h2&gt;
&lt;p&gt;
	Now that we have chosen a chess engine and have an understanding how to communicate with it we should look at how to incorporate that into our iOS and macOS application. Since stockfish is written in C++ (&lt;a href=&quot;https://github.com/official-stockfish/Stockfish&quot;&gt;source code&lt;/a&gt;) the best option to make the engine available to our Swift application is by bridging it in a Objective-C++ framework. I created a new Swift package with one target containing the stockfish source code as well as some wrapper implementation. When using the stockfish engine the source code expects you to send commands on stdin and receive the response on stdout. To make this work with our iOS application we create a new pipe for reading and one for writing and redirect stdin and stdout to those pipes. Fortunately a function to do exactly this already exists in the C standard library ready for us to use it.
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-objc&quot;&gt;- (void)start {
    // set up read pipe
    _readPipe = [NSPipe pipe];
    _pipeReadHandle = [_readPipe fileHandleForReading];

    dup2([[_readPipe fileHandleForWriting] fileDescriptor], fileno(stdout));

    [[NSNotificationCenter defaultCenter]
     addObserver:self
     selector:@selector(readStdout:)
     name:NSFileHandleReadCompletionNotification
     object:_pipeReadHandle
    ];

    [_pipeReadHandle readInBackgroundAndNotify];

    // set up write pipe
    _writePipe = [NSPipe pipe];
    _pipeWriteHandle = [_writePipe fileHandleForWriting];
    dup2([[_writePipe fileHandleForReading] fileDescriptor], fileno(stdin));

    _queue = dispatch_queue_create(&amp;quot;ck-message-queue&amp;quot;, DISPATCH_QUEUE_CONCURRENT);

    dispatch_async(_queue, ^{
        _engine-&amp;gt;initialize();
    });
}

- (void)stop {
    [_pipeReadHandle closeFile];
    [_pipeWriteHandle closeFile];

    _readPipe = NULL;
    _pipeReadHandle = NULL;

    _writePipe = NULL;
    _pipeWriteHandle = NULL;

    [[NSNotificationCenter defaultCenter] removeObserver:self];
}

- (void)sendCommand: (NSString*) command {
    dispatch_sync(_queue, ^{
        const char *cmd = [[command stringByAppendingString:@&amp;quot;\n&amp;quot;] UTF8String];
        write([_pipeWriteHandle fileDescriptor], cmd, strlen(cmd));
    });
}

# pragma mark Private

- (void)readStdout: (NSNotification*) notification {
    [_pipeReadHandle readInBackgroundAndNotify];

    NSData *data = [[notification userInfo] objectForKey:NSFileHandleNotificationDataItem];
    NSArray&amp;lt;NSString *&amp;gt; *output = [[[NSString alloc] initWithData:data encoding:NSUTF8StringEncoding] componentsSeparatedByString:@&amp;quot;\n&amp;quot;];

    [output enumerateObjectsUsingBlock:^(NSString * _Nonnull obj, NSUInteger idx, BOOL * _Nonnull stop) {
        [self responseHandler](obj);
    }];
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;p&gt;
	With this wrapper in place we can start to implement the UCI protocol and interface with the chosen engine implementation.
&lt;/p&gt;
&lt;h2&gt;
	Using a chess engine
&lt;/h2&gt;
&lt;p&gt;
	We need 4 core components:
&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;
		&lt;p&gt;
			A model to represent engine commands
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			A parser to parse engine responses
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			An interface to send commands to the engine and to receive responses from it (done)
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			An engine representation to bring all of this together
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
	For reference I included parts of this implementation for you to get a better understanding how my integration works. Please note that while I changed the implementation quite a bit in my current project this code was initially taken from this open source package: &lt;a href=&quot;https://github.com/chesskit-app/chesskit-engine&quot;&gt;chesskit-engine&lt;/a&gt;.
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-swift&quot;&gt;public enum EngineCommand: Equatable {
	case uci
	case isready
	case position(PositionString, moves: [String]? = nil)
	...
}

class EngineResponseParser {
    static func parse(response: String) -&amp;gt; EngineResponse? {
        let tokens = response.split { $0.isWhitespace || $0.isNewline } .map(String.init)
        var iterator = tokens.makeIterator()

        guard let command = iterator.next() else {
            return nil
        }

        switch command {
        case &amp;quot;id&amp;quot;:          return parseID(&amp;amp;iterator)
        case &amp;quot;uciok&amp;quot;:       return .uciok
        case &amp;quot;readyok&amp;quot;:     return .readyok
        case &amp;quot;bestmove&amp;quot;:    return parseBestMove(&amp;amp;iterator)
        case &amp;quot;info&amp;quot;:        return parseInfo(&amp;amp;iterator)
        default:            return nil
        }
    }

    // ...
}

public class Engine {
    private let messenger: EngineMessenger
    public private(set) var isRunning = false
    private var startupLoop: EngineSetupLoop

    private let queue = DispatchQueue(
        label: &amp;quot;ck-engine-queue&amp;quot;,
        qos: .userInteractive
    )

    deinit {
        stop()
    }

    public func start(
        coreCount: Int? = nil,
        multipv: Int = 1,
        completion: @escaping () -&amp;gt; Void = {}
    ) {
        startupLoop.startupDidComplete = {
            self.isRunning = true
            self.performInitialSetup(
                coreCount: coreCount ?? ProcessInfo.processInfo.processorCount,
                multipv: multipv
            )
            DispatchQueue.main.async {
                completion()
            }
        }

        messenger.responseHandler = { [weak self] response in
            guard let self else { return }

            guard let parsed = EngineResponse(rawValue: response) else {
                if !response.isEmpty {
                    self.log(response)
                }
                return
            }

            if !self.isRunning, let next = startupLoop.nextCommand(given: parsed) {
                self.send(command: next)
            }
            
            DispatchQueue.main.async {
                self.receiveResponse(parsed)
            }
        }

        messenger.start()
        send(command: .uci)
    }

    public func stop() {
        guard isRunning else { return }

        send(command: .stop)
        send(command: .quit)
        messenger.stop()

        isRunning = false
        initialSetupComplete = false
    }
	
	public func send(command: EngineCommand) {
        guard isRunning || [.uci, .isready].contains(command) else {
            return
        }

        queue.sync {
            messenger.sendCommand(command.rawValue)
        }
    }

    public var receiveResponse: (_ response: EngineResponse) -&amp;gt; Void = {
        _ in
    }

    private var initialSetupComplete = false

    private func performInitialSetup(coreCount: Int, multipv: Int) {
        guard !initialSetupComplete else { return }

        let fileOptions = [
                &amp;quot;EvalFile&amp;quot;: &amp;quot;nn-1111cefa1111&amp;quot;,
                &amp;quot;EvalFileSmall&amp;quot;: &amp;quot;nn-37f18f62d772&amp;quot;
            ].compactMapValues {
                Bundle.main.url(forResource: $0, withExtension: &amp;quot;nnue&amp;quot;)?.path()
            }
        fileOptions.map(EngineCommand.setoption).forEach(send)

        send(command: .setoption(
            id: &amp;quot;Threads&amp;quot;,
            value: &amp;quot;\(max(coreCount - 1, 1))&amp;quot;
        ))
        send(command: .setoption(id: &amp;quot;MultiPV&amp;quot;, value: &amp;quot;\(multipv)&amp;quot;))

        initialSetupComplete = true
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;p&gt;
	If you are wondering what those EvalFiles are about here is a quick rundown for you:
	
	Both Stockfish and Leela Chess Zero require neural network files to be provided to the engine for computation. They can be downloaded on their respective website and will be added to the engine via the setoption command. You are free to chose your options on how to provide the engine with these files. You might want to consider downloading them at app launch or maybe you just bundle them with the application in the first place.
&lt;/p&gt;
&lt;h2&gt;
	Game Review
&lt;/h2&gt;
&lt;p&gt;
	One thing popular chess platforms like lichess offer to their users is a detailed game review analysis. It boils down to categorizing moves as blunders, mistakes and inaccuracies with the help of a chess engine. This information can provide great value when analyzing your games to quickly spot interesting parts of the game and to identify fields of improvements for your chess training.
&lt;/p&gt;
&lt;p&gt;
	Another useful metric is the average centipawn loss.
	
	Centipawn loss refers to the difference in evaluation scores given by a chess engine before and after a move. This score is expressed in centipawns, which is one-hundredth of a pawn. A lower centipawn loss indicates better move quality, while a higher centipawn loss suggests a poorer decision. The average centipawn loss further describes the average of all centipawn losses throughout the game. The calculation of this metric is done with the following algorithm:
&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;Analyze Each Move&lt;/strong&gt;: After the game is completed, use a chess engine to analyze each move. For each move, record the evaluation score before and after the move.
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;Calculate Centipawn Loss for Each Move&lt;/strong&gt;: &lt;code&gt;Centipawn Loss = Evaluation Before Move - Evaluation After Move&lt;/code&gt;. This formula gives you the centipawn loss for each move. If the evaluation after the move is lower than before, the result will be a positive centipawn loss, indicating a drop in position quality.
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;Sum the Centipawn Losses&lt;/strong&gt;: Add up all the individual centipawn losses for the moves made during the game.
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;Count the Number of Moves&lt;/strong&gt;: Determine the total number of moves made in the game.
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;Calculate Average Centipawn Loss&lt;/strong&gt;: &lt;code&gt;ACPL = Total Centipawn Loss / Number of Moves&lt;/code&gt; This formula provides the average centipawn loss over the course of the game.
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
	As of this writing I did not have any time to look into that more closely but it is one of the features I would like to tackle next.
&lt;/p&gt;
&lt;h2&gt;
	Closing words
&lt;/h2&gt;
&lt;p&gt;
	Thats all I have for this topic. In the last part I&apos;d like to draw a conclusion as well as say a few words about unit tests.
&lt;/p&gt;
		</content>
	</entry>
	<entry>
		<title type="text">Writing a chess app (7/9): Chess puzzles</title>
		<id>https://davidvonk.dev/swift/writing-a-chess-app-7-9-chess-puzzles</id>
		<link href="https://davidvonk.dev/swift/writing-a-chess-app-7-9-chess-puzzles" rel="alternate">
		</link>
		<updated>2024-10-31T15:52:00Z</updated>
		<summary type="text">
			A blog post series detailing my journey of developing a chess app for iOS and macOS
		</summary>
		<content type="html">
			&lt;h2&gt;
	What are chess puzzles?
&lt;/h2&gt;
&lt;p&gt;
	Chess puzzles are specially crafted scenarios in which players are presented with a specific position on the chessboard. The objective is to find the best move or sequence of moves to achieve a particular goal, such as checkmating the opponent, winning material, or escaping from a difficult situation. These puzzles serve as a training tool for players of all skill levels, from beginners to grandmasters.
&lt;/p&gt;
&lt;h3&gt;
	Types of Chess Puzzles
&lt;/h3&gt;
&lt;ol&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;Checkmate Puzzles&lt;/strong&gt;: These puzzles require the player to deliver checkmate in a certain number of moves. They are often categorized by the number of moves needed to achieve checkmate, such as &quot;mate in 1,&quot; &quot;mate in 2,&quot; etc.
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;Tactical Puzzles&lt;/strong&gt;: These focus on specific tactical themes, such as forks, pins, skewers, and discovered attacks. Solving these puzzles helps players recognize tactical opportunities during real games.
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;Endgame Puzzles&lt;/strong&gt;: These involve positions that arise in the endgame phase of chess. They often test players&apos; understanding of key endgame concepts and techniques.
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;strong&gt;Defensive Puzzles&lt;/strong&gt;: In these scenarios, the player must find the best defensive move to avoid losing material or getting checkmated.
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
	To conclude puzzles are of tremendous help in improving your overall chess skills especially in terms of pattern recognition. This is the reason why I wanted to incorporate puzzle training into my chess training app.
&lt;/p&gt;
&lt;h2&gt;
	Datasource for chess puzzles
&lt;/h2&gt;
&lt;p&gt;
	Fortunately lichess offers a huge catalog of chess puzzles you can use in your application. At the time of writing the database consists of &lt;strong&gt;4,211,138&lt;/strong&gt; puzzles which are also categorized.
&lt;/p&gt;
&lt;p&gt;
	On their &lt;a href=&quot;https://database.lichess.org/#puzzles&quot;&gt;website&lt;/a&gt; they state:
&lt;/p&gt;
&lt;blockquote&gt;
	&lt;p&gt;
		Lichess games and puzzles are released under the &lt;a href=&quot;https://tldrlegal.com/license/creative-commons-cc0-1.0-universal&quot;&gt;Creative Commons CC0 license&lt;/a&gt;. Use them for research, commercial purpose, publication, anything you like. You can download, modify and redistribute them, without asking for permission.
	&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;
	And I think that is wonderful.
&lt;/p&gt;
&lt;h2&gt;
	Implementation
&lt;/h2&gt;
&lt;p&gt;
	In the previous parts we already talked about SAN, FEN and PGN Parsing. We also have a catalog of UI components which can be used to display a chess board and play moves. GRDB.swift is integrated into project as well to help with reading from a sqlite database. Therefore everything is in place to build the puzzle feature in the application.
&lt;/p&gt;
&lt;p&gt;
	I downloaded a database dump and added it to my app project. Next I created some models to read from it via GRDB.swift. Creating a list of possible categories and adding some puzzle modes was trivial with the help of SwiftUI. I added two playing modes:
&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;
		&lt;p&gt;
			Puzzle Streak: Trying to solve as many puzzles as possible without a mistake, with each puzzle getting trickier.
		&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;
			Puzzle Storm: Trying to solve as many puzzles as possible in a limited amount of time.
		&lt;/p&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
	This is something which existing online platforms like lichess solve pretty well already. However I wanted to add this functionality to my app as well to have a full featured application solving all my various needs in terms of training my chess skills.
&lt;/p&gt;
&lt;p&gt;
	In the upcoming part of this series we will examine chess engines and how we can leverage them in our project.
&lt;/p&gt;
		</content>
	</entry>
	<entry>
		<title type="text">Writing a chess app (6/9): Spaced repetition repertoire training</title>
		<id>https://davidvonk.dev/swift/writing-a-chess-app-6-9-spaced-repetition-repertoire-training</id>
		<link href="https://davidvonk.dev/swift/writing-a-chess-app-6-9-spaced-repetition-repertoire-training" rel="alternate">
		</link>
		<updated>2024-10-31T14:52:00Z</updated>
		<summary type="text">
			A blog post series detailing my journey of developing a chess app for iOS and macOS
		</summary>
		<content type="html">
			&lt;p&gt;
	You probably already heard about the term &lt;a href=&quot;https://en.wikipedia.org/wiki/Spaced_repetition&quot;&gt;Spaced repetition&lt;/a&gt;. Maybe you even used spaced repetition training when learning for an exam or something like this. The most popular online platform to deal with spaced repetition is &lt;a href=&quot;https://apps.ankiweb.net/&quot;&gt;Anki&lt;/a&gt; flashcards. In chess spaced repetition also I widely known as one of the best techniques to memorize a repertoire and to learn the various moves. Online platforms like &lt;a href=&quot;https://chessable.com&quot;&gt;Chessable&lt;/a&gt; make use of this learning technique to provide valuable tools to chess players.
	
	One of the more recent developments in this area is the FSRS(Free Spaced Repetition Scheduler) algorithm which I am currently using to develop this feature for my app.
&lt;/p&gt;
&lt;h2&gt;
	FSRS algorithm
&lt;/h2&gt;
&lt;p&gt;
	I probably won&apos;t describe this algorithm better than its developer Jarrett Ye. So without further explanation I highly recommend you to read up on this algorithm through these links:
&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;a href=&quot;https://github.com/open-spaced-repetition/fsrs4anki/wiki/ABC-of-FSRS&quot;&gt;Overview&lt;/a&gt;&lt;/p&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;p&gt;&lt;a href=&quot;https://github.com/open-spaced-repetition/fsrs4anki/wiki/The-Algorithm&quot;&gt;Reference&lt;/a&gt;&lt;/p&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
	Furthermore a pretty solid implementation for Swift already exists online on GitHub which is why I didn&apos;t look into building my own package and instead decided to build upon this existing one: &lt;a href=&quot;https://github.com/4rays/swift-fsrs&quot;&gt;swift-fsrs&lt;/a&gt;.
&lt;/p&gt;
&lt;p&gt;
	Instead I&apos;d like to focus more on the parts I did implement on my own which is the actual repertoire training and how to chose which move to learn and schedule next.
&lt;/p&gt;
&lt;h2&gt;
	Tree data structure
&lt;/h2&gt;
&lt;p&gt;
	A chess repertoire can be represented as a tree, where each node corresponds to a position in a game, and the edges represent possible moves. The root of the tree is the starting position, and the leaves represent the end of a line or a position that has been thoroughly studied. When using a tree data structure we want to look at two main traversing algorithms:
&lt;/p&gt;
&lt;h3&gt;
	1. Depth-First Traversal
&lt;/h3&gt;
&lt;p&gt;
	Depth-first traversal (DFT) explores as far down a branch of the tree as possible before backtracking. This method can be particularly useful for in-depth study of a specific line in a repertoire.
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-swift&quot;&gt;func depthFirstTraversal(node: ChessNode) {
    // Mark the node as visited
    visit(node)
    
    // Recursively visit each child node
    for child in node.children {
        depthFirstTraversal(child)
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;h3&gt;
	2. Breadth-First Traversal
&lt;/h3&gt;
&lt;p&gt;
	Breadth-first traversal (BFT), on the other hand, explores all nodes at the present depth level before moving on to nodes at the next depth level. This approach is beneficial for ensuring a well-rounded understanding of the repertoire.
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-swift&quot;&gt;func breadthFirstTraversal(root: ChessNode) {
    var queue: [ChessNode] = [root]
    
    while !queue.isEmpty {
        let node = queue.removeFirst()
        visit(node)
        
        // Add all child nodes to the queue
        queue.append(contentsOf: node.children)
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;p&gt;
	To effectively schedule the next move in a chess repertoire using spaced repetition, you can combine the traversal algorithms with a spaced repetition algorithm. Here’s how you might integrate them:
&lt;/p&gt;
&lt;p&gt;
	If there are any moves markes as &quot;due for review&quot; present them to the user. If all due moves are reviewed, choose the first move which isn&apos;t reviewed yet based on the chosen tree traversal algorithm. Once the user reviewed this move calculate the next interval at which the move should be reviewed again.
&lt;/p&gt;
&lt;p&gt;
	For completeness sake I will provide you with my current implementation of a chess game tree which I use to implement the presented algorithms:
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-swift&quot;&gt;@Observable
public final class Game: CustomStringConvertible, Identifiable, Hashable, Equatable {
    public private(set) var current: GameNode
    public private(set) var root: GameNode
    public private(set) var tags: [String: String]

    init(root: GameNode, tags: [String: String]) {
        self.root = root
        self.current = root
        self.tags = tags
    }
    
    public convenience init(tags: [String: String]) throws {
        if let fen = tags[&amp;quot;FEN&amp;quot;] {
            let position = try Position(fen: fen)
            let node = GameNode(position: position)
            self.init(root: node, tags: tags)
        } else {
            self.init(root: GameNode(), tags: tags)
        }
    }
    
    public convenience init() {
        self.init(root: GameNode(), tags: [:])
    }

    public static func == (lhs: Game, rhs: Game) -&amp;gt; Bool {
        lhs.id == rhs.id
    }
    
    public func hash(into hasher: inout Hasher) {
        hasher.combine(id)
    }

    public var id: UUID {
        root.nodeId
    }

    public var ply: Int { current.ply }
    
    public var isAtBeginning: Bool {
        current.isTopNode
    }
    
    public var isAtEnd: Bool {
        current.variations.isEmpty
    }
    
    public func goForward() {
        guard let next = current.variations.first else { return }
        self.current = next
    }
    
    public func goBackward() {
        guard let parent = current.parent else { return }
        self.current = parent
    }
    
    public func goToBeginning() {
        go(to: root)
    }
    
    public func goToEnd() {
        while !isAtEnd {
            goForward()
        }
    }
    
    public func go(to node: GameNode) {
        self.current = node
    }
    
    public func go(to id: UUID) {
        guard let match = root.search(for: id) else { return }
        go(to: match)
    }
    
    public func play(move: Move) throws {
        let newPosition = try current.position.play(move: move)
        let newNode = GameNode(position: newPosition, move: move, parent: current)
        
        let existingNode = current.variations.first { $0.move == move }
        
        if let existingNode {
            go(to: existingNode)
        } else {
            add(node: newNode)
        }
    }
    
    public func add(node: GameNode) {
        current.variations.append(node)
        go(to: node)
    }
    
    public func addMainline(node: GameNode) {
        current.variations.insert(node, at: 0)
        go(to: node)
    }
    
    public func remove(node: GameNode) {
        node.parent?.variations.removeAll(where: {
            $0.nodeId == node.nodeId
        })
    }
    
    public func remove(id: UUID) {
        guard let match = root.search(for: id) else { return }
        remove(node: match)
    }
    
    public func promote(node: GameNode) {
        let variationStart = node.variationStart
        guard let parent = variationStart.parent else { return }
        guard let index = parent.variations.firstIndex(where: {
            $0.nodeId == variationStart.nodeId
        }) else { return }
        if index &amp;gt; 0 {
            parent.variations.swapAt(index, index - 1)
        }
    }
    
    public func promoteToMainline(node: GameNode) {
        let variationStart = node.variationStart
        guard let parent = variationStart.parent else { return }
        guard let index = parent.variations.firstIndex(where: {
            $0.nodeId == variationStart.nodeId
        }), index != 0 else { return }
        
        parent.variations.removeAll(where: {
            $0.nodeId == variationStart.nodeId
        })
        parent.variations.insert(variationStart, at: 0)
    }
    
    public func demote(node: GameNode) {
        let variationStart = node.variationStart
        guard let parent = variationStart.parent else { return }
        guard let index = parent.variations.firstIndex(where: {
            $0.nodeId == variationStart.nodeId
        }) else { return }
        if index &amp;lt; parent.variations.count - 1 {
            parent.variations.swapAt(index, index + 1)
        }
    }
    
    public func traverse(from node: GameNode, visit: (GameNode) -&amp;gt; Void) {
        visit(node)
        for variation in node.variations {
            traverse(from: variation, visit: visit)
        }
    }
    
    public func traverseMainline(from node: GameNode, visit: (GameNode) -&amp;gt; Void) {
        visit(node)
        if let next = node.variations.first {
            traverseMainline(from: next, visit: visit)
        }
    }
    
    public var uciPath: [String] {
        current.reconstructMovesFromBeginning().map(\.uci)
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;h2&gt;
	Bonus: Finding deviations of your repertoire in your online games
&lt;/h2&gt;
&lt;p&gt;
	One last bonus before we finish up this part of the blog post series. One main motivation for building my own chess training application was to learn my new repertoire. This meant of course building the spaced repetition feature for training the repertoire.
&lt;/p&gt;
&lt;p&gt;
	One feature I could not find on any of the available platforms though was to analyze my online games in the context of my repertoire. On my MacBook this is fairly simple to do since I can open multiple windows to open my repertoire in some chess database software next to my online game. On iOS this is rather tricky and the user experience left me frustrated.
&lt;/p&gt;
&lt;p&gt;
	Since my application stores my repertoire already I decided to integrate with the lichess and chess.com APIs to download my online games. With the game information available I was able to build a feature where each move of my online games is compared to my repertoire database. If my opponent or I deviate from my repertoire I mark this in the move notation view and provide a link to the respective position in the repertoire. With this little change I now quickly can see where my repertoire needs to be expanded as well as which parts of my repertoire I have trouble with recalling.
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-swift&quot;&gt; func checkForDeviation() {
    for move in moves {
        let fen = position.make(move: move).fen
        if await !database.findMoveInRepertoire(for: playerSide, fen: fen) {
            // did not find position in repertoire
        }
    }
}

func findMoveInRepertoire(for side: Repertoire.Side, fen: String) async -&amp;gt; Bool {
    do {
        return try await reader.read { db in
            if try Repertoire
            .filter(Repertoire.Columns.side == playerSide)
            .joining(required: Repertoire.positions.filter(RepertoirePosition.Columns.fen == fen))
            .fetchOne(db) == nil {
                return false
                } else {
                    return true
                }
            }
    } catch {
        return false
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
		</content>
	</entry>
	<entry>
		<title type="text">Writing a chess app (5/9): Database Schema and move encoding</title>
		<id>https://davidvonk.dev/swift/writing-a-chess-app-5-9-database-schema-and-move-encoding</id>
		<link href="https://davidvonk.dev/swift/writing-a-chess-app-5-9-database-schema-and-move-encoding" rel="alternate">
		</link>
		<updated>2024-10-31T13:52:00Z</updated>
		<summary type="text">
			A blog post series detailing my journey of developing a chess app for iOS and macOS
		</summary>
		<content type="html">
			&lt;p&gt;
	Hello and welcome to the next part of my ongoing blog post series of writing a chess app for iOS and macOS.
	
	In this part I&apos;d like to talk about my design decision regarding the database schema.
	
	So lets dive in.
&lt;/p&gt;
&lt;h2&gt;
	Database Schema
&lt;/h2&gt;
&lt;p&gt;
	For the database schema I heavily leaned on on the work of &lt;a href=&quot;https://github.com/nguyenpham/ocgdb&quot;&gt;ocgdb&lt;/a&gt;. It is an open database format, is actually quite performant to store and search chess games and is the best excuse to use one of my favourite Swift packages (&lt;a href=&quot;https://github.com/groue/GRDB.swift&quot;&gt;GRDB.swift&lt;/a&gt;). Besides the obvious benefits the open source chess database software &lt;a href=&quot;https://encroissant.org&quot;&gt;En Croissant&lt;/a&gt; also uses the exact same database format and so my choice was being made.
&lt;/p&gt;
&lt;p&gt;
	For reference here is the sqlite schema which I think is pretty self explanatory:
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;CREATE TABLE Info (
    Name TEXT UNIQUE NOT NULL,
    Value TEXT
);

CREATE TABLE Events (
    ID INTEGER PRIMARY KEY AUTOINCREMENT,
    Name TEXT UNIQUE
);

CREATE TABLE Sites (
    ID INTEGER PRIMARY KEY AUTOINCREMENT,
    Name TEXT UNIQUE
);

CREATE TABLE Players (
    ID INTEGER PRIMARY KEY,
    Name TEXT UNIQUE,
    Elo INTEGER
);

CREATE TABLE Games (
    ID INTEGER PRIMARY KEY AUTOINCREMENT,
    EventID INTEGER,
    SiteID INTEGER,
    Date TEXT,
    Round INTEGER,
    WhiteID INTEGER,
    WhiteElo INTEGER,
    BlackID INTEGER,
    BlackElo INTEGER,
    Result INTEGER,
    TimeControl TEXT,
    ECO TEXT,
    PlyCount INTEGER,
    FEN TEXT,
    Moves BLOB,
    FOREIGN KEY(EventID) REFERENCES Events,
    FOREIGN KEY(SiteID) REFERENCES Sites,
    FOREIGN KEY(WhiteID) REFERENCES Players,
    FOREIGN KEY(BlackID) REFERENCES Players
);

CREATE INDEX IF NOT EXISTS games_date_idx ON Games(Date);
CREATE INDEX IF NOT EXISTS games_white_idx ON Games(WhiteID);
CREATE INDEX IF NOT EXISTS games_black_idx ON Games(BlackID);
CREATE INDEX IF NOT EXISTS games_result_idx ON Games(Result);
CREATE INDEX IF NOT EXISTS games_white_elo_idx ON Games(WhiteElo);
CREATE INDEX IF NOT EXISTS games_black_elo_idx ON Games(BlackElo);
CREATE INDEX IF NOT EXISTS games_plycount_idx ON Games(PlyCount);
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;p&gt;
	If you had a closer look at the schema you might have noticed that the &lt;code&gt;Moves&lt;/code&gt; column is specified as a &lt;code&gt;BLOB&lt;/code&gt;. The idea behind that design decision is discussed in our next chapter.
&lt;/p&gt;
&lt;h2&gt;
	Move Encoding
&lt;/h2&gt;
&lt;p&gt;
	When thinking about how to encode moves into the database several options come to mind. The obvious solution is to store the movetext just as a &lt;code&gt;TEXT&lt;/code&gt; column and move on. I opted for encoding every chess move with only 2 bytes. This not only makes the actual data that is saved pretty small it also makes encoding and decoding moves trivial. Of course this could be optimized even further but weighting performance and ease of use against each other I ultimately found this solution to be the best fit for my needs.
&lt;/p&gt;
&lt;p&gt;
	As we learned at the beginning of this blog post series a chess board has 64 squares and a move can be represented by moving a piece from one square to another square. The piece does not have to be stored itself, since this information is typically retrieved from a FEN string which encodes a chess board quite efficiently. There is a special case when moving a pawn to the backrank of your opponent resulting in promoting your pawn to a queen, knight, bishop or rook. So we need to account for that. If we represent the various promotion options with an integer enum we end up with a single integer ranging from 0-4 to encode a promotion information:
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-swift&quot;&gt;enum Promotion: Int {
	case empty
	case queen
	case bishop
	case rook
	case knight
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;p&gt;
	With this in place a move representation can look something like this:
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-swift&quot;&gt;typealias Square = Int

extension Square {
	var rank: Int {
	    value &amp;gt;&amp;gt; 3
	}
	
	var file: Int {
	    value &amp;amp; 0x7
	}
}

struct Move: Hashable, Equatable, Sendable {
    let from: Square
    let to: Square
    let promotion: Promotion
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;p&gt;
	There is room for improvement though. You could represent a square with a struct conforming to &lt;code&gt;RawRepresentable&lt;/code&gt; and &lt;code&gt;ExpressibleByIntegerLiteral&lt;/code&gt; to actually not pollute the &lt;code&gt;Int&lt;/code&gt; namespace with our extensions but this is something I haven&apos;t looked into yet. As a bonus I added some code to retrieve the file and rank of a given square.
&lt;/p&gt;
&lt;p&gt;
	Looking at the above representation of a move lets count how much bits we need to actually store this information.
	
	We need 6 bits for each square (2^6 = 64) and 2 bits (2^2 = 4) to store the promotion information adding up to 14 bits in total which easily fits in an UInt16 or 2 bytes. For completeness sake here are the respective encoding and decoding functions:
&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;
	&lt;pre&gt;&lt;code class=&quot;language-swift&quot;&gt;init(encoded: UInt16) {
    let from = encoded &amp;amp; 63
    let to = encoded &amp;gt;&amp;gt; 6 &amp;amp; 63
    let promotion = (encoded &amp;gt;&amp;gt; 12) &amp;amp; 7
    let promotionRole = Promotion(rawValue: Int(promotion))
    self.init(from: Square(from), to: Int(to), promotion: promotionRole)
}

var encoded: UInt16 {
    UInt16(from) | UInt16(to) &amp;lt;&amp;lt; 6 | (UInt16(promotion.rawValue)) &amp;lt;&amp;lt; 12
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/figure&gt;
&lt;p&gt;
	And with that lets move on our next part which will look at spaced repetition training of repertoires.
&lt;/p&gt;
		</content>
	</entry>
</feed>